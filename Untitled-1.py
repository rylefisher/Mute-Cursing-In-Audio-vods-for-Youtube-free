\n\nclass AudioTranscriber:\n def __init__(self, model_size="large-v3", device="cuda"):\n global MODEL\n try:\n self.model = MODEL\n except Exception as e:\n print(\n f"Error loading model: {e} Dont panic, I got this. You should really use nvidia for good results."\n )\n self.model = stable_whisper.load_model("medium", device="cpu")\n self.audio_paths = []\n self.index = len(self.audio_paths) - 1\n self.clean_audio_paths = []\n self.srt_paths = []\n self.srt_paths_small = []\n self.clean_json = ""\n self.clean_json_paths = []\n self.srt_small = ""\n self.text_paths = []\n self.text_parts = 0\n\n def add_time(self, time_str, minutes=1):\n """Add minutes to SRT timestamp, adjusting for fractional seconds."""\n base_time = datetime.strptime(time_str.split(",")[0], "%H:%M:%S")\n milliseconds = int(time_str.split(",")[1]) if "," in time_str else 0\n added_time = base_time + timedelta(minutes=minutes, milliseconds=milliseconds)\n return added_time.strftime("%H:%M:%S,") + f"{milliseconds:03d}"\n\n def srt_combine(self, paths):\n combined_content = ""\n subtitle_number = 1\n additional_minutes = 0\n\n for index, file_path in enumerate(paths):\n if index > 0:\n combined_content += (\n  "\n\n" \n )\n with open(file_path, "r", encoding="utf-8") as file:\n lines = file.readlines()\n i = 0\n while i < len(lines):\n line = lines[i].strip() \n if line.isdigit():\n  combined_content += f"{subtitle_number}\n" \n  subtitle_number += 1\n elif "-->" in line:\n  start_time, end_time = line.split(" --> ")\n  combined_content += f"{self.add_time(start_time, additional_minutes)} --> {self.add_time(end_time, additional_minutes)}\n"\n else:\n  combined_content += line + "\n" \n i += 1\n additional_minutes += 1\n\n name = Path(paths[0]).stem\n output_file_prt = Path(paths[0]).parent.parent / f"{name}.srt"\n with open(str(output_file_prt), "w", encoding="utf-8") as file:\n file.write(combined_content)\n\n def transcribe_audio(self, audio_path, language="en", beam_size=5):\n """Transcribe the given audio file and return the transcription result."""\n self.audio_paths.append(audio_path)\n self.json_paths = []\n return self.model.transcribe(\n audio_path,\n compression_ratio_threshold=5,\n verbose=True,\n word_timestamps=True,\n language=language,\n )\n\n def save_transcription(self, audio_path, result, small=False):\n """Save the transcription to .srt and .json files based on the audio file path."""\n if small:\n audio_path = audio_path.replace(".wav", "_small.wav")\n if "wav" in audio_path:\n srt_path = audio_path.replace(".wav", ".srt")\n txt_path = audio_path.replace(".wav", ".txt")\n json_path = audio_path.replace(".wav", ".json")\n else:\n srt_path = audio_path.replace(".mp3", ".srt")\n json_path = audio_path.replace(".mp3", ".json")\n print("outputting transcript files")\n\n if not small:\n result.to_srt_vtt(srt_path, word_level=False)\n result.to_txt(txt_path)\n self.text_paths.append(txt_path)\n self.srt_paths.append(srt_path)\n self.text_parts += 1\n else:\n result.to_srt_vtt(srt_path, word_level=False)\n self.srt_small = srt_path\n\n result.to_txt(f"{srt_path}".replace(".srt", ".txt"))\n result.save_as_json(json_path)\n self.json_path = json_path\n print("completed transcript files")\n\n if small:\n self.srt_paths_small.append(srt_path)\n else:\n self.srt_paths.append(srt_path)\n\n def censor_cursing(self, audio_path):\n return process_audio(audio_path, self.json_path)\n\n def transcribe_and_censor(self, audio_path):\n """Process an audio file, transcribe it and save the results."""\n result = self.transcribe_audio(audio_path)\n resultSmall = result\n result.split_by_length(max_chars=42)\n self.save_transcription(audio_path, result)\n resultSmall.split_by_length(max_chars=35)\n self.save_transcription(audio_path, resultSmall, True)\n aud, self.clean_json = self.censor_cursing(audio_path)\n self.clean_audio_paths.append(aud)\n self.clean_json_paths.append(self.clean_json)\n\n\n\ndef main(audio_path, video_):\n global transcript_paths\n transcript_paths = []\n print("loading model")\n transcriber = AudioTranscriber(model_size=MODEL_SIZE, device="cuda")\n print("finished")\n log_ = JSONLog(audio_path)\n enums = split_audio(audio_path, "output")\n temp_folder = None\n if enums:\n for counter, audio_path in enumerate(enums):\n if not temp_folder and audio_path:\n temp_folder = Path(audio_path).parent.__str__()\n print("wav_file_path type:", type(audio_path))\n print("wav_file_path content:", audio_path)\n print(\n f"\n\nProcessing {audio_path}...@@@@@@@@@@@@@@@@@@@\n\nindex {counter+1} of {len(enums)}\n\n@@@@@@@@@@@@@@@@@@@\n\n"\n )\n transcriber.transcribe_and_censor(audio_path)\n\n\n else:\n print(f"Processing {audio_path}...")\n transcriber.transcribe_and_censor(audio_path)\n try:\n combine_txt_files(transcriber.text_paths)\n except Exception as e:\n print(str(e))\n\n comb_path = combine_wav_files(transcriber.clean_audio_paths)\n\n transcriber.srt_combine(transcriber.srt_paths)\n transcriber.srt_combine(transcriber.srt_paths_small)
